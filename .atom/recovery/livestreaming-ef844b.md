# 動画配信基礎知識

## 動画を見るには?
- 通常ダウンロード
HTTP

- プログレッシブダウンロード
HTTP
受信しながら放送

- Streaming
生放送
受信しながら放送

- HTTP Adaptive Streaming
HTTP、生放送
受信しながら放送

![image1](/Users/ml200/Desktop/images/スクリーンショット 2019-07-18 7.36.59.png)

## プロトコル
- HLS


- RTMP
レイテンシ低い。


## HTTP上のストリーミング
- HLS★
Appleの規格。ITunesでの審査必須。

- HDS
Adobe

- Smooth Streaming
Microsoft

- MPEG-DASH
ISO規格
プレイヤの対応少ない

## 配信の種類
- オンデマンド配信
録画した動画を配信する
通常の動画を配信するだけ

- ライブ配信（リニア配信）
収録中の映像をリアルタイムで変換し、配信。

## その他
- ビットレート(bps)
1秒あたりどれくらいのサイズか
ストレージ容量、転送量にあたいする。


- フレームレート(fps)
1秒あたり何枚の画像にするか。
多いほどなめらか

- ABR
アダプティブ・ビットレートと呼ばれている動画配信ツールを指します。
ストリーミング再生時のビットレートや解像度を視聴環境に応じて自動的に変更する仕組みです。
配信側がプレーヤーのコンテンツの再生状態を監視し、
常に自動的に最適のビットレート値に切り替える機能を有しているため、
高画質でありながら安定した配信を実現することができます。


## ファイルの構造
- コンテナ
映像データと音声データを組み合わせた箱

- コーデック
圧縮/伸長の形式。
エンコードとデコードをあわせたもの。
音声コーデックと映像（ビデオ）コーデックに分かれる。
音声 ･･･ AAC,MP3など
映像 ･･･ H.264,HEVC(H.265) など

AV1が今後来ると言われている。
現在の主流はH.264(MPEG-4 AVC)

エンコードされた形式とデコードできる形式が合ってないと見れない。聞けないなどが発生する。

- エンコード
大きい容量のデータを圧縮すること

- エンコーダー
エンコードするハードやソフトウェア
エンコーディングではフレームやブロック単位で前後のフレームとも
比較しながら圧縮処理を行っていくため、CPUに掛かる負荷が高く、処理に時間が掛かります。

- デコード
圧縮されたデータをもとに戻すこと

- トランスコーダー（ディング）
エンコードされたものを別の形式に変換する。またはするソフト、ハード。
再エンコードするわけではない。
再エンコードを伴わないため、画質の劣化がなく処理も高速に行われます。
例えば、MPEG-2からMPEG-4への変換、MP4からMPEG-DASHへの変換をトランスコーディングと呼びます。

- パッケージング
MP4などの動画ファイルをインターネット上で配信するために適したMPEG-DASHなどの配信プロトコルに変換することです。
トランスコーディングや必要に応じてDRMによる暗号化を行うプロセスを含みます。


## サーバーの種類
- インジェストサーバー
インジェスト ･･･ 収録したメディアから編集用ストレージへ映像データを移動すること

- ストリーミングサーバー
- HTTPサーバー
通常の録画ファイルを配信するサーバー

- MediaProxy
AbemaTV内の造語?
GCS/mongoに保存している多種なデータをHLS形式で出力するもの。

## 配信の流れ
- Origin
Origin サーバ、映像を受け付けるサーバのこと
Publisher から映像を受取り、このサーバで受け付けた映像は配信するための形式に変換され、
Edge サーバから取り出され Viewer に届けられる
必要に応じて Publisher から受け取ったストリームを変換することもある (transcode)

- Edge
Edge サーバ、映像を配信するサーバのこと
映像は Origin サーバから取り出して配信を行う
多数の Viewer が接続する、そのため同じストリームの接続は束ねられ複数の Viewer が居ても
Origin への接続数を減らす役割を持っている (offload)
Viewer の利用するプロトコルに応じて Edge は映像の届け方を変えている

- Publisher
映像の配信元、配信者のこと
カメラやマイクから受け取った映像・音声データは Publisher 側でエンコードし、
映像データとして Origin に送信している

- Viewer
映像を見る端末、視聴者のこと
視聴者には利用環境に応じて、視聴形態が違う

撮影データと音声データをエンコーダー(FMLE/OBS)で変換しながらストリームを流している。
映像を受け付けるサーバー



### AbemaTVの場合
![image4](/Users/ml200/Desktop/images/スクリーンショット 2019-07-18 8.39.59.png)
撮影する
ネットに上げるためにエンコードする。


![image2](/Users/ml200/Desktop/images/スクリーンショット 2019-07-18 8.29.03.png)
撮影:
Wirecastを通してエンコードして、GCP上のWowzaへストリーミング

エンコード/パッケージング:
Wowzaでストリーミングされた映像(1080p)を各種解像度ごとに再エンコード（トランスコード?）し、
HLSへのパッケージングもおこなう。
生放送管理画面での操作も行う。

監視/保存:
watchmanは、mongoにセグメント情報、redisとGCSにオブジェクトデータに書き込む。

配信/広告挿入:
映像を再生するためのプレイリストやTS（動画ファイルの保存形式の一つ）のエンドポイントを持つサービス。

配信からユーザーまで:
MediaProxyからはプレイリスト、CDNからTSを取得。




#### 開局まで
AbemaTVの開発期間は4ヶ月ほど（異常なくらい爆速）
人員が揃っている、もともとweb動画配信のサービス(AbemaStudio)とかスタジオとかはあったらしい。
機能: 番組表、ユーザー管理、シェア機能、編成管理ツール、トランスコーダー、インジェストサーバー
（ダウンロード、追っかけ再生、）
![image3](/Users/ml200/Desktop/images/スクリーンショット 2019-07-18 8.37.58.png)

AbemaTV (1周年)
840 instance vCPU 3000 RAM 13TB  → $60,000/month
230 nodes vCPU 3700 RAM 3300GB → $110,295/month

仮開局から本開局までに
生番組の配信（ライブトランスコーダー、パッケージャー）、広告、コメント


スタジオ撮影のみであれば、中で自社用にちゃんと工事した機材を用意してみたいな感じでできるが、
外だと会場から配信できるかみたいなのは考えないと行けない。


撮影する
エンコードしながらストリーミングサーバーにアップロードする
それを配信する。

AbemaTVとかの構成のとき何が必要になってくるか。

//////////////////
/// クラウドエース
//////////////////

- サーバー
MAX
フル外注
MIN
一部外注


ヒアリング
利用規模人数: 年間100万人
デイリー、マンスリーアクティブ: 想定レベル。
5万とか10万人くらいなら標準環境でいけちゃう。

配信先プラットフォーム: iOS、アンドロイド(会員)

チャンネル目標: 未確定
目標視聴者数:
アーカイブ:
→ CDN: 下り時に課金発生

以下、要確認
自社スタジオ && youtube → 専用線つくればアップロード可能（専用線が半年とか工事待ちの可能性も）
外スタジオ && youtube → 専用線ないと無理(要工事？)あと申請が必要
自社スタジオ && フルスクラッチ → 回線次第
外スタジオ && フルスクラッチ → 回線次第

要点
- youtube + googleの専用線のパッケージで全体的に安くなるとかプランもある。
→ 他社的に事例もないそうで対外的にアピールできる部分もあるそう
→ アプリのつなぎこみも簡単になるので価格、期間を抑えられる可能性あり
→ データ分析はこの場合別のパートナーと組む必要あり

- 同社と組むに当たり、想定規模や個人情報等のポリシーなどのビジネスサイドやガバメントの要件の提出が必要
  (ex. ビジネスドメイン、マネタイズ、配信チャンネル数、デイリーアクティブユーザー数等)

- プッシュ通知とかの機能によってはそちらの負荷のほうが大きい可能性もある。

懸念点
- 専用線がないとライブ配信自体がきついとの指摘あり
- 専用線の工事が遅く半年以上前くらいから申込みの準備をすすめる必要ありそう
→ 他社との面談含めて確認していく

今後の動き
- 撮影〜配信構成と金額感をパターン別にまとめることを優先的に実施
- 技術的な部分の調査引き続き


youtube + Google cloud interconnect? で全体的に安くなるとかプランもある。
→ 他社的に事例もないそうで対外的にアピールできる部分もあるそう
→ ネットワークGCP直結線は3~6ヶ月かかったりする。回線系はクラウドエースに一括で申し込めるがどこも工事とか遅い。
→ アプリへはyoutubeの環境つなぎ込むだけでOKなので簡単
→ データ基盤とかアナリティクス系の情報はクラウドエースとは別のアナリティクス系パートナーが窓口になる

基本的には専用回線がないときついとのこと。要確認
→ 他の場所からの中継のとき回線工事が必要になる
→ 自社スタジオ/中継 と プラットフォーム自作/youtubeでそれぞれどうなるのか

abemaもAWSを一部は使っている（cloud Front）


以下、クラウドエースに今後提供していくべき情報
- サービス
ビジネスドメイン、マネタイズ
集客 ~ 配信までの大まかな想定
中継先何拠点で何人の受信者の想定か
想定年間利用規模人数
想定デイリー/マンスリーアクティブユーザー(目標視聴者数)
  → 5~10万人であればGCPの標準環境でいける。
チャンネル数（同時刻のライブ配信はあるか / 1日）

配信先プラットフォームは何か
  → iOS / Android

- LiveUの範囲
LiveUでどこまでいけるのか
ストリーミングサーバーへのアップとか
GSCに直接行けるか三信電気に聞く。


- アプリ
プッシュ通知的な、メッセージング負荷。
10万人に配布するならそっちのほうが負荷かかったりするので事前に情報

- ポリシーについて
Two側でガバナンスの定義はしてほしい。個人情報の扱いとか
GCPの設定をするにもそこがないとなかなか難しい

来月添付資料入れて再度コンタクト。



////////////////////////////////////
/// クラウドエース 2回目 (20190829)
////////////////////////////////////

インターコネクト
PRの件

安定
GCPでの事例としてクラウドエースさんに紹介してもらう。
GCPとyoutubeのpeeringはサポート外。
GCPでフルスクラッチ構成。

フルスクラッチ
youtube使わないほうがいい。
youtubeならyoutubeだけ。ただクラウドエースさんはyoutubeサポートなし
ビジネスとして組み込めるか。

請負、準委任
常駐は相談次第。
サーバー構築系のジョインも可能。
SIのコンサル、開発OK

ブースト
やりたいことと粒度。



//////////////////////////////////////////////////////
////  確認項目
//////////////////////////////////////////////////////
- API処理をGAEでダウンゼロで処理できるのかは不安
- youtubeはデータが取れるかどうかft社に確認(30分テレカン?)
    - でもダッシュボードもいざみたいときにないとまずいのでyoutubeなしかも
- 負荷検証、データベースでの運用(spanner)の確認
- spanner, bq, pubsubあたりを聞く。

心配な点は
- 負荷検証
    → 新関さん入ってもらえる
- Spanner運用
    → 一番心配なのでcloudboost希望
 - bq/pubsubのパイプライン系

cloud boostの希望事項
Spannerでの一般的なECサイトの構築のワークショップ
→ 細かい部分はこっちで実際に手を動かす。
→ きつそうならデータベースエンジニアを期間限定(特定フェーズ?)で派遣してもらう。


NTT確認
- ライブ配信中のユーザー分析ができるかどうか
- youtubeでビジネス要件難しそう。




































//////////////////
/// トップゲート
//////////////////

構築/アドバイザリー
アプリ開発の枠組み(golang)

動画配信系のアプリ/サーバー構築実績はなし。
グーグルにはコンタクトして進めていくつもり

まずは見積もりがファーストゴール。
こっちもインフラは把握しながらやっていきたい。

見積もりの希望
時期:来年夏
金額:
大（アベマのテレビ）
中（セミナー系）
小（youtuber系）
トップゲート開発時期は準備でき次第。

配信方法とか。
端末の解像度の想定が大事。
規模的には2000万。
トップゲート 単価120万なので、1年見込みだと6000万はかかるかも。

webじゃなくて端末だけでいけるんじゃ？

ビジネスサイドの情報必要ならNDAすぐに結ぶ。
要件定義 → プロトタイプ → 要件洗い出し → 開発
プロトタイピングの契約から。

要件定義見積もり
開発概算見積もり

まずはNDAを結ぶ。
場合によっては事業計画書ももらいたい




//////////////////
/// 三信電気 LiveU
//////////////////
2019/07/19

撮影機材はどうしたらいいか。
wowza streamingにながすのか。
管理コンソールはどうなっているのか。
→ LiveUで配信、受信
管理コンソールはネット環境あればOK。
管理コンソールで送信先と、ストリーミングサーバーも選択できる。
どうやって配信しているのか。

abema子会社の紹介とかできる。
トライキャスターはスイッチ（ハード）アベマで使用
https://jp.newtek.com/tricaster/tc1/

↓あとで価格表もらう。
LU600
  4K 500万
  HDMI 380万?
LU300
  300万 有線も可能
LU500は廃盤

2台で撮影してライブユーで送り先を変える。
冗長構成で2台で同じものを撮影しているとこもある。
販売価格にサーバーもセット。

LiveUだけでもライブ配信だけなら流せるが、
テロップとかいるならスイッチャー（2,3カメラとかでもいける）とサブ室も必要。

専用のエンコーダーがあったりする。
スイッチャーのアウトにエンコーダー（エレメンタル）→ ハード(100万とか)
https://www.ctcsp.co.jp/products/elemental/live.html

LiveUで受信した先のエンコーダー → ワイヤーキャスト（ソフト） 5,60万のPCで動いている。
https://www.telestream.net/wirecast/

外注 or 機械を買うか
アベマは買っている。
毎週やるなら買っちゃったほうが良さそう。

テレビ側でアップコン、ブラビアの機能で
1秒のディレイ。安定度によって秒数を遅らせる。
受信機4つまでいける。

ライブユーのサーバー管理は自社エンジニアでも行ける。
ミキサー、スイッチャーは制作会社とかでやってくれる会社もある。
現場はカメラマンとディレクターくらいでいい。

ハンディカメラ4K 4、50万
スタジオカメラだと数百万。

LiveU購入したら図面とかも引いてくれる。サポート有り

スペシャル系の番組でアポロプロダクション
1番組どれくらいか → 数百万とかまでいかず、数十万くらい。

レンタル1日10万
1週間20万。

ブライトコープ
https://www.brightcove.com/ja/


//////////////////
/// PLAY
//////////////////

配信〜運用パッケージで提供している。
端末検証とかで負荷になる。新しい端末のサポートとか。
jsのタグいれるだけで見れる。

サポート部分で厚く対応してくれる。
CDNで配信なので、視聴者数によっては従量課金になる。
毎月1時間番組2000人で終わる。
月間10配信 9000GB
9TB → 単価15円 x 15~20万
2万人だと150万程度
VOD 8万で400本格納できる。


スイッチング
→ 8人、外注も使う
渋谷にスタジオもある。貸出OK。別途料金。
セミナーを小さくやるくらい。


2カメ1番組 1h
事前準備含め6hで30万〜
レイテンシ 30秒~

回線
やれるけど不安定
光回線を専有すること 100MB
複数回線。複数チャンネル。

youtube
広告、スポンサーついたときに
広告を回すタイミングの調整
映像のスイッチングであればなんでもできる。

AbemaTvのライブ手伝うレベルのクオリティではある。

LiveU
回線引けないとこは良い。
引けた方が安定する。
しょっちゅう使っている。
サーバーからの共用回線ではきつい。

ゴルフ場とかで映像送ることはできる。
専用サーバーからの回線が大事。

リアルタイム分析 → 過去1時間
ユーザー判別もできる。

アプリ制作会社紹介もある。開発もやっている。

DRM → 動画保護


- 機材のレンタル含めた撮影で2カメ構成準備含め6hで1本30万前後で実施可能
→ 改めてそちらの資料もらう
→ AbemaTVのライブを手伝えるレベルのクオリティとLiveUという最有力の配信機材の取り扱いに慣れている

- サーバーのサービスについては月8万~（規模、容量で従量課金）
→ 1回の配信2万人規模だと150万/月くらい、従量課金についての資料抜けてたので要求中
→ リアルタイムでの動画分析、コンテンツ保護の連携も可能

- ネットワークについて
→ 受信側サーバーは共有回線でなくて専有回線であれば十分配信可能なレベルにはなる。
→ 中継はLiveUだけで、スタジオに受信サーバーとそれをつなぐ専有回線あればアップロードも問題ない
→ 手軽だが従量課金になる部分は内製で大幅に減らせる可能性ありなのでサービス自体の魅力が薄め
→ 料金表に不明な部分多いので改めて依頼中。

懸念点
- 動画保護（DRM）の観点も認識しておくべきである




//////////////////
/// NTTSC
//////////////////

アプリ制作 → パートナーで外注。
java、Goでも行けるが確認。同社はCDNが得意。
広島記念式典 → 全世界に配信。

エンコード技術者派遣もしているが簡単にできる。
wowzaメディアシステム。AWS使うこともある。CDNは独自。
IX直結ダイレクトコネクト。
214Gbpsの堂島全世界は苦手。AWSでもできる。マルチCDN環境もできる。 50:50という方法もできる。
国内ならAWSより月額固定できるので安く抑えられる。
GB/数円
同時アクセス6万2千でも賄うことができた。

週2だとスポットになる。
オーダーメイドだと特設サイト作成撮影〜配信までできる。
→ 1ショット
都内 / 50万〜60万 1カメ 1PC ミキサー有り 1日フル
撮影クルー/アシスタント
別でサーバー料金
特設サイトはなし。

同月で2回3回やるなら常設でやったほうが良い。
共用1GbpsCDNの流用
流用が5000人とかなら単純に5倍になるわけではない。

1時間配信(3600s)で1Mbpsのとき
1Mbps x 3600s / 8 = 450MB / 1024 = 0.439GB x 1000人 = 約450GB
1000人 → 共有1Gbps 450GB
AWS → 4500円 → 5万円
それだとAWSのほうが安い可能性。
2000~3000人だとNTT安くなる。
週4/4週
AWS → 90万
NTT → 20万（最初のスピード感は遅いけど）
インジェストにwowza

アーカイブ化するとエンコーディングとストレージで従量課金になる。
ローカルのカメラで録画したやつをアップすれば100GBまで10万で行ける。
これもwowza、ストレージは独自
サーバー、ストレージ、CDN

Jstream
同じVODでも自動でトランスコーディングしてくれる。
プレイヤータグでCDN
インジェストからまるっとやってくれる。中間全部。
従量課金

Liveshell 議会中継、ライブ配信系くらいなら問題ない。
回線の引き込みもやってくれる。
1ヶ月前に家庭用の共用でも行ける。
上り10MG 1080p
激しいものでも60フレーム。
1日50~60万でも

プロトコルによっては



要点
官公庁のライブ配信（議会や記念式典）のバックエンド使用の実績あり
独自のCDN環境を持っているため月額固定(20万円〜)で実施可能で、条件によってはAWSと月額で70万ほど抑えられる場合も。
容量の追加は10万/月単位だが調整も可能
2週間デモ環境でテスト配信可能


懸念点
配信のデータ容量と同時視聴人数がトレードオフの関係にあるため
より良い画質と想定視聴人数の擦り合せをテストしていく必要がある。


今後の動き
ネットワーク周りの構成調査
想定の規模/最適な画質のときの金額感を確認。
→ ユーザー/クオリティ/金額のトレードオフなのでもう少し先の段階で調整する必要あり


//////////////////
/// NTTSC 2回目
//////////////////

◆ リアルタイム分析のとこはメディアプレイヤーとラーニングシステム周りがセットになっているものが大半
→ NTTラーニングシステムと提携するパターンあり。
→ インプレッション課金なので、視聴数が多ければ多いほど課金。(theoプレーヤー)
→ 一方でID課金のパターンあれば良い。
→ とはいえ、リアルタイムでコンテンツの抑揚を支持するパターン少ないかもなので、アナリティクス(48hディレイ)で試してみる。
→ NTTSCビデオプラットフォーム（提案いただいているものとは別製品）もインプレッションなので合わない。

ここの分析系とアプリのベンダー含めて調査、提案いただく予定。

◆ 見積もり
常時配信契約と大型イベント契約2パターンの契約
まずはデバッグとして先に開発期間の契約。


ニーズとして分析、特にE-Learningで
NTTグループでシステムを委託して座組を持ち合わせている。
NTTラーニングシステムの管理画面に入って見る。
学習に特化したものなので、いくつか選択してできる。
NTT経由しなくても分析。
URLをシステムにプレーヤーでの分析
ラーニングシステム周りは提案いただける。メディアプレイヤーとセット。
theoプレーヤー
ラーニングシステムはID課金
videoJs OSS入れてアナリティクス API連携
LMS
API連携して分析
HLS受け取れる。
メディアプレーヤーと分析。

2000人はASPでさばける。
万人キャッシュサーバースポット契約

アプリ制作 golang
スカパー -> play株式会社

アプリのメモリ、落ちない。
listen radio
FM放送 


アナリティクスで動画分析試してみる。


//////////////////
/// Jstream
//////////////////

コンテンツの制作、配信のサポート
フジテレビのオンデマンドの実績。
ウェブ制作くらいはできる。
アプリ → 外注
Jstreamにはプロデューサー
フジテレビオンデマンドは内製
自社CDN（ベンダー）、国内のみ
AWSだと動画どうするの？
マルチCDN、AWSとかマルチCDN
基本ライブはJsteramのCDNを利用。
ストリーミングサーバーも自社。
サービスだと1年契約
1500GB 月16回 1時間番組HD 16時間/月
2400Kbps 720p
事前だと16万。30万/月

準備に4時間、早朝土日。1.5倍
1時間で100万いかないくらい。
社内メンバー + 子会社
フィットネスクラブの会員向けにオアシス

//////////////////
/// パンダスタジオ見学
//////////////////

- 機材
種類
金額
スペック
 ビットレート
 解像度


- 撮影された映像の完成度

- ネットワーク
インターネット階層
他会場
ライブ配信するスタジオかどうか。


ライブであまりやっていることが少ない。
ダメ出しが多かったりして、一発で決まることが少ない
ライブもどきでやることがほとんど。
天井の高さ2F分5m、部屋自体は58坪
編集ようにカメラ回すパターンもある
LiveUsoloでやっているとこも
カメラからは収録機につないであってカメラと収録機で録画2本同時に行う。
SSD480GB
線は2Gbps3本 nurobiz
ntt共用 700Mbps 基地局 本線と予備選
マイクバウンダリー
ビジネス用と個人用でビジネス用
kddiの近くで沢山お金払ってやっと借りられるものもある
360インチ




Cloud Next確認事項

Cloud interconnectの工事期間、どれくらい前に申し込めばいいか、金額確認
自社スタジオもってなければ意味ないのか。
工事はgoogleがするのか、ラストワンマイル。
引き込みの設定。
工事自体に金額はかからないとか。
他会場で専用線引く場合に工事費だけでいけるか。

pdf持ち回って確認する。
8月までに
トップゲート2番

1. wowzaのローカルのデータをwatchしてGCSにリクエストする。
2. wowzaのVMとGCSをfuseしてマウントする。 → こっちだとカスタマイズが柔軟じゃなかったりする。





# まとめ
## 機材について
LiveShellX 7万
LiveU LU600 500万(4K) 
LiveU LU300 300万(HD) レンタル10万/d 20万/w


TC1 100万~500万（スイッチャー）

## プラットフォームについて
従量課金が大半で想定ユーザー数、動画の質によって変わるため一概に比較できていない。


1. 撮影 → エンコード → NTTサーバー → プレイヤー
メリット
- 手軽
- サーバーは定額制
- プレイヤーのカスタマイズできる


デメリット

費用感
40万~/月

↓詳細
- ストリーミングサーバー
◆初期費用 5万(VOD) / 5万(ライブ)
◆ランニング 10万〜 / 20万〜
共用1Gbpsにつき+10万円

2Mbps x 1000人 → 2Gbps 30万 + 下記プラットフォーム?

- プラットフォーム???
◆初期費用 5万
◆ランニング 4.5万〜
◆従量課金
 ディスク容量※1※3（GB） 200円
 再生回数※4(1000再生） 200円
 配信流量※4（GB） 9円
 ※1：元動画容量＋トランスコード後動画容量の合計を指します。
 ※3：当月の最大値にて従量課金致します。
 ※4：当月の累積値にて従量課金致します。

+DRM対策可能 12万/月（月・5万回再生※9 50,000円）
+API 2万/月

うまく連携してストレージとか抑えられる場合も


2. 撮影 → エンコード → youtube → プレイヤー
専用線使わないパターンも可
※youtubeで見るわけでなくて、アプリにyoutubeプレイヤーを埋め込む
メリット
- 手軽
- ほぼ無料
- 対外的アピールになる（国内で専用線+youtubeの事例がないので

デメリット
- Googleの専用線を敷くと一気に高額?
- プレイヤーのカスタマイズ不可。（投げ銭機能的なのができない）

専用線
2Gbps*3 = $1,230 + データ量（下り $0.042/GB)??
※プラスでプロバイダ側の料金がかかる??（20万前後/月??）
初期費用数万円


3. 撮影 → エンコード → サーバー → GCS → CDN → プレイヤー
メリット
- 内製化できるのでデータとかも好きに取れる
- カスタマイズ性

デメリット
- 管理費用（トラブル、デバイス）
- 開発費用
- 期間が必要


費用
wowza $65/台&月
その他サーバー 30万/月前後??規模による
開発(外注)に120万/月以上



google 
inter→youtubeしていない
オンプレ→GCP
金額高め
GCP → youtube
peering

ダイレクトにはやっていない。
おんぷれ → GCP → youtube


サマソニ youtube
ソフトバンクプロバイダ
APIに接続
インターネットの接続に聞く

youtubeの基盤にAPIで流す。
castify ライブ配信SDK
ニコニコ作っていた人。裏はGKE

広告出る出ない。出る可能性がある。
広告のでないビジネスプラン→ないかも。

無料なのでサポートはない。

コンサルサービス
- トラブル時はサポートから$100とか
  → 実際に入れる人が限られている。
- サーバーの構成とかプリセールスエンジニアに聞くことができる。
  → 無料でできる。製品だと回答できるけど実装が難しいかもしれない。spanner使ってリクエストタイム減りませんみたいな相談はできる。
- コンサル
  → 年間のGCP利用料で億単位/年




youtubeチームに聞く

広告無しでのライブ配信
nextのライブは広告なし、アーカイブも広告なし。

弊社アプリから会員限定でyoutubeからのライブ配信を見せたい。
youtubeの限定公開??
アプリだけでyoutubeの動画を見せるようにしたい。
ライブ配信自体にAPIがあるか
代表アカウントで認証

動画を見た属性分析をしたい。リアルタイム。
youtubeのデータに関してはアナリティクス系のパートナーに相談できると聞いた。
ライブ管理画面でできるかどうか。
本日youtubeアカウント開いたのでまだライブ管理画面は見れる状況でないです。


アプリでサブスクリプション会員に見せたい
認証アカウントに限定公開して、
APIでgoogleアカウント認証をしてyoutubeAPIを使って実現するというイメージを持っていますが、あっていますか。





///////////////////////////////////////////////////////////////////
//////
//////  クラウドネイティブサービスで実現するライブ動画配信
//////
///////////////////////////////////////////////////////////////////

目次
- クラウドネイティブサービスで実現するライブ動画配信
- WinTicketにおける競輪ライブ配信システムの実現
- ライブ配信基盤としての活用 - B2B製品｢V-CUBEセミナー｣
- Amazon Cloud Frontをライブ配信で活用するメリット



1. wowzaをEC2で利用する
2. マネージドサービスを利用する。 ◎
3. Saasを利用する


# クラウドネイティブサービスで実現するライブ動画配信
amazon 廣瀬

ライブ配信の基礎/課題/アーキテクチャーパターン

## ライブ配信とは
動画コンテンツを配信すること。
UGC(ユーザーから配信)

## 方法
VOD - youtube、amazonprime
LIVE - youtubelive、abema、音楽、スポーツ (数秒から数十秒の遅延)
双方向性 - テレビ会議（遅延が許容できないパターン）

## 背景
サイトの滞在時間が伸び、コンテンツの認知度、SEOにも有効
VOD以上に集中的に集客が高い。FBの統計で3倍10倍
安定した端末が普及


## 基礎
- プログレッシブ
単一のメディアファイルをダウンロードしつつデータを再生、ライブ未対応。
シンプルで標準的なwebサーバーで配信できる。

- ストリーミング
メディアデータを細かく分割して順次配信。


### ストリーミング
- Streaming protocol
RTMP持続接続型
専用プレーヤーが必要。
CPUリソースが大量に必要。

- HTTPストリーミング ⭕
デバイスの標準プレーヤやプラグインで再生できる
CDN技術を使用。
サポート体制の見極め

### HTTPストリーミング
- MediaSegmentFile
2~10秒くらいの分割された動画


- ManifestFile
時間に対応するメディアセグメントファイルのURIを羅列させたリスト

1. プレイヤーは視聴したい動画のマニフェストをゲット 
配信サーバーは該当するマニフェストファイルをレスポンス。
2. マニフェストファイルに記載されたメディアセグメントファイルのURLをみて要求してGETしていく。
ライブ中なので定期的に更新される。プレーヤーは常に要求している。
追加されたメディファイルを順次をGET


### マルチビットレート(ABR)
ユーザーが様々な環境に対応できるように最適化されたコンテンツ配信
動的なビットレートの対応。
回線が良いと高ビットレート。

ABRのデメリットは？？

### インジェスト方法
- 衛生、専用線伝送
莫大な費用かかる。気軽にはできない。

- インターネット伝送
ベストエフォート、安定性を保つために工夫が必要。
TCPvsUDP 
→ TCPだと一貫性はあるがパケロスがでたときに再送のオーバーヘッド（遅延）が起きて最終的には再生が停止したりする。
UDPベースのプロトコルが注目されている。Zixi, Rist


### 課題
1. 耐障害性
リアルタイムで配信している、トランスコーディングしている。
各コンポーネント間で1つでも止まったらライブも止まるのでパイプラインは冗長化する必要がある。
配信ソースからオリジンまで冗長化するべきである。
ソフトウェアエンコーダーでもPCがハングしたら死亡なので冗長化がよろしい。

2. 多様化する配信要件
マルチデバイス、ABR、HLS、DRM、アーカイブ、巻き戻し(DVR)、VODキャスト、広告

3. スパイクアクセス
一斉にマニフェストファイルとセグメントファイルのリクエストが起きる。
1セグメントあたり、2秒1クライアント毎秒1回のリクエストが発生する計算。
データが膨大なので大容量にたえられる、キャッシュTTLが短いファイルを効率的に配信できるCDN
確実に保存できるオリジンが重要。

### 課題を解決するマネージとサービス
AWS Media Services
米Elementalが展開していた配信サービスをAWSで展開
6つのサービス
Cookpad、葵ゼミ、NewsPicksのアーキテクチャー

要件に合わせて組わせることも可能。

1. シンプル（MediaLive MediaStore Cloud Front）
- MediaLive
並行してライブ配信可能
SCTE-35
静止画のオーバーレイ
配信パイプラインが標準で冗長化。
冗長化しないタイプで60%の料金で利用できるシングルパイプラインチャンネル。

- MediaStore
オリジン。動画メディアに最適化されたストレージ兼オリジンサービス
S3との違いは結果整合性 → 古いファイルを参照してしまう可能性があって、マニフェストファイルが更新されない可能性ある。
ライブ配信時のマニフェスト更新、一貫性を保たないといけない。
内部的にS3を持ちつつも一貫性を保ちながらできる。

- CloudFront
動画再生がキャッシュされるので、安定する。
CDN側にリクエスト負荷を寄せることができるのでオリジンの保護、
コンテンツがリアルタイムに生成されているのでキャッシュ意味ないんじゃない？
最初にキャッシュミスしたリクエストがオリジンに返送されている間、
ほぼ同時に来たリクエストを僅かな時間一時停止させてその間に最初のリクエストオリジンにリクエストを転送して
エッジ側にキャッシュが乗っかったタイミングで待たせているリクエストに対してレスポンスする動きをとる。
末端のエッジとオリジンの間にリージョナルエッジキャッシュ。中間キャッシュを含めて効率的な配信を実現。


2. MediaStoreをMediaPackageに置き換える。
HLSだけでなくMPEG-DASH、DRMとかにも対応したいとなったらこれ。
再生制御とかも可能。
HLSからその他のマルチフォーマットに対応。DRM、タイムシフトとかの再生制御に対応したオリジン。
副系に切り替えてもユーザーに影響ない。
VODもリクエストに応じてパッケージングできるようになった。


3. オンデマンド
MediaLiveからS3に出力それをcloudfront経由で配信させる。
コンバートとかつかえる。処理時間が短縮。
VODは一貫性必要ないので安いS3で十分。
QVBR


4. FILE/LIVEをスケジュール配信したい。
FILE→LIVE→FILE→LIVEとか。
MediaLiveのスケジュールアクションを利用。

5. 広告
メディアテイラーを利用。

6. 同時配信台数増減
ライブチャンネルを予め登録しておいてスタート・ストップ
チャンネルの起動スタート・ストップを使用。



# WinTicketにおける競輪ライブ配信システムの実現
https://www.cyberagent.co.jp/service_product/winticket
全国43会場のライブ配信（全競輪会場）
AbemaTVと連動
ライブ映像は競輪会場からもらっている。


# 要件
- ライブ
競合より同等以下の配信遅延を抑えたい。
start-over再生とタイムシフト機能は必要ない。
→ HLSで配信（AWS Elemental）

- ハイライト映像
競輪側で編集されたものをもらう。
プログレッシブ(MP4) S3で配信。

# 構成
43箇所ある競輪会場からシャトーアメーバにデータを貰っている。
ライブシェルX使っていてAWSでにインジェスト
MediaProxy（パッケージ部分）メンテとかめっちゃしんどい。コスト削減
バック5人、インフラ1人、web5人、PM2人

## 競輪場
競輪場に新たにエンコーダーを設置。
専用回線でシャトーアメーバに伝送。
Abemaで使うので編集するのに伝送させている。
映像は2種類
競輪場がパブリックに流している映像と何もない素の映像。

## シャトーアメーバ
番組配信収録スタジオ
競輪のスケジュールそって映像を受信している。
43箇所から5~13会場毎日
KDDI,Softbankでシャトーまで伝送。受信してLiveSHELLX
競輪場にあるエンコーダーから同軸にIPに変換して
対になるIPエンコーダーをシャトーにおいてライブシェルに入れている。
競輪場からシャトー、シャトーからメディア・ライブラリーもすべて冗長化で2回線分専用回線を利用。

## エレメンタル周り
13箇所で動的にすると複雑だったので、各競輪場ごとにインプットとチャンネルを用意。
2系統準備
配信の時間のみ起動。終了したら停止。
エンコードパラメータチューニングはAbemaのスタッフにやってもらっている。

## メディアパッケージ
各競輪場ごとにインプットとチャンネルを持っている。
2系統入力でフェイルオーバー試験も実施。

## LamdaとAPI（管理画面）
どこにインジェトするかの管理画面を提供。
スケジュール確認、チャンネルの操作、アイドル状態、ランニングなのか確認できる。
管理画面につかうだけなのでEC2でなくてもサーバーレスでコスト削減できていいかなって感じで。

配信日フィルターとインスタンス状態。開始、終了時刻。
詳細ページもある。
インスタンス起動停止、実際の画面。
フタ絵 → しばらくお待ち下さいとか。
入力元rtmpエンドポイントとか
各ビットレートごとに確認できるツール。

## セットアップ
cloudformation go言語
livepackagemediafrontroute53

## チャンネル管理
43チャンネル + ステージング + デベロップメント
チャンネル管理は提供されていない。
命名規則でやっっている。競輪場コードがあるのでそれをプレフィクスでやっている。
現在はタグづけできるけど当時はなかった。
でもDB使いたくなくて命名規則で頑張った。

競輪場→スタジオ→AWS→ユーザー

コメント:
オンプレだと1億かかるけど1/10くらいになったんじゃない？


# ライブ配信基盤としての活用 - B2B製品｢V-CUBEセミナー｣
https://jp.vcube.com/service/seminar/overview/function/streaming.html

ビデオストリーミング配信に移行中。
同時視聴2万人規模。 / 同時配信数 最大数百件程度
もともとの課題
安定性、
今後の拡張性、同時配信数/視聴数の上限が頭打ち。
コンポーネント利用時のAPI不足
配信設定の選択肢が少ない。帯域、解像度


AWS MediaService
wirecast、OBSだと普通のユーザー使えない。
V-CUBE製配信アプリ

手前にEC2をwowzaでおいている。固定IP
ソウルリージョンに同じものをやっている。
メインを東京、サブを韓国（他社CDN）

API（SDK??）が充実している。

現状
EIPのアタッチできない
MediaLiveの詳細ログ見れない。
packageの遅延。
Medialiveプレビュー





# Amazon Cloud Frontをライブ配信で活用するメリット

CDNの必要性
インターネット自体とオリジンの負荷を下げる。
需要に合わせたキャパシティの提供

下りだけ。
ユーザーに近いとこで配信してオリジンの負荷を下げる。ネットワーク自体の負荷を下げて安定的な映像の提供。
いろいろなISPを通るので問題あるとこにいく可能性を下げる。

エンドユーザー
数を増やす。
peeringDB
ハリケーン エレクトリック


バックエンド
オリジンにデータを取りに行かないといけない
cloud frontを使うと中間省いてすぐ近くにcloudがつながっているようなもの。
https://infrastructure.aws/


FT社
youtubeだと会員限定なくて、オープンになってします。
クローズドだとyoutubeでない。

ディズニーは配信システムはあくまで先方なので、連携。
メディアプレイヤーも用意されたもの。
→ akamai
オンデマンド配信。
CDNで得意先がCMS連携できるサービス。

メディアプレーヤーの分析
マーベルデラックス
再生はOS標準。
データ解析 AdobeAnalyticsイベント発行でデータ送信
ユーザーがどういう操作したかわかる。

何秒でとかの計測はしていない。
OSだとスタート・ストップは検知できる。


サードパーティはセキュリティ要件でNG（できれば）。
new relicで入れて分析を補っていた。
管理は得意先のCMSで実施。

ふぃっとねすで標準OSメディアプレーヤーに分析つけるで問題ないか
→ 運用フローによる、オペレーターのリテラシーによる。高い人向け。
標準でもそんな変わらない。多機能になっているので、運用部分くらいのものしか変わらない。


ストア側のアプリ経験あるか。
実績はないけど要件次第ではいける。
IDが一緒なら一緒にやったほうが良い。
ビーコン系はある。展示会場とか。

どうしてもgolangなら外部パートナー探して。
品質•速度で言ったらUnityとか。

ロードマップ、スケジュール、規模感



スマホがリモコン
入ってからコンテンツを選択。
















































//
